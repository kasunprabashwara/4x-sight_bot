{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11749745,"sourceType":"datasetVersion","datasetId":7376279},{"sourceId":386974,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":319047,"modelId":339613},{"sourceId":390974,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":321975,"modelId":342596}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sb3-contrib torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"4ebEBoC0gfJ1","outputId":"421e0ca7-9b58-437c-eea2-3cae301ae44c","execution":{"iopub.status.busy":"2025-05-13T18:58:55.356398Z","iopub.execute_input":"2025-05-13T18:58:55.356598Z","iopub.status.idle":"2025-05-13T19:00:21.979698Z","shell.execute_reply.started":"2025-05-13T18:58:55.356580Z","shell.execute_reply":"2025-05-13T19:00:21.978814Z"}},"outputs":[{"name":"stdout","text":"Collecting sb3-contrib\n  Downloading sb3_contrib-2.6.0-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nCollecting stable_baselines3<3.0,>=2.6.0 (from sb3-contrib)\n  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nCollecting gymnasium<1.2.0,>=0.29.1 (from stable_baselines3<3.0,>=2.6.0->sb3-contrib)\n  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.26.4)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.1.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.7.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.20->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2024.2.0)\nDownloading sb3_contrib-2.6.0-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, gymnasium, stable_baselines3, sb3-contrib\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n  Attempting uninstall: stable_baselines3\n    Found existing installation: stable-baselines3 2.1.0\n    Uninstalling stable-baselines3-2.1.0:\n      Successfully uninstalled stable-baselines3-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.1.1 which is incompatible.\nkaggle-environments 1.16.11 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.6.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sb3-contrib-2.6.0 stable_baselines3-2.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom itertools import combinations\n\nfrom gymnasium import Env\nfrom gymnasium.spaces import Box, Dict\n\nimport torch as th\nimport torch.nn as nn","metadata":{"trusted":true,"id":"4wilzsT-gfJ3","execution":{"iopub.status.busy":"2025-05-13T19:00:21.980693Z","iopub.execute_input":"2025-05-13T19:00:21.980976Z","iopub.status.idle":"2025-05-13T19:00:25.452860Z","shell.execute_reply.started":"2025-05-13T19:00:21.980946Z","shell.execute_reply":"2025-05-13T19:00:25.452294Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndef get_forex_data():\n    # Load the dataset\n    data_set = pd.read_csv('/kaggle/input/hourly-rates-v2/Hourly_Rates_v2 (1).csv', na_values='ND', parse_dates=['Timestamp'])\n    \n    # Interpolate missing values to handle missing data\n    data_set.interpolate(inplace=True)\n    \n    # Select only the required columns\n    df = data_set[['Timestamp','EURUSD', 'GBPUSD','JPYUSD']].copy()\n    \n    \n    return df\ndef get_pair_price_from_row(row, pair, base_currency):\n    \"\"\"\n    Given a row (a pandas Series) and a pair (tuple of two currencies),\n    return the exchange rate defined as:\n      - If the second currency equals the base, then the price is assumed to be available\n        in the column f\"{non_base}{base_currency}\".\n      - If the first currency equals the base, then the price is 1/(price from f\"{other}{base_currency}\").\n      - Otherwise, compute the cross rate as (price of A in base)/(price of B in base).\n    \"\"\"\n    A, B = pair\n    if A == B:\n        return 1.0\n    if B == base_currency:\n        return row[f\"{A}{base_currency}\"]\n    elif A == base_currency:\n        return 1.0 / row[f\"{B}{base_currency}\"]\n    else:\n        return row[f\"{A}{base_currency}\"] / row[f\"{B}{base_currency}\"]","metadata":{"trusted":true,"id":"2dKKr-DPgfJ5","execution":{"iopub.status.busy":"2025-05-13T19:00:25.454613Z","iopub.execute_input":"2025-05-13T19:00:25.455390Z","iopub.status.idle":"2025-05-13T19:00:25.460583Z","shell.execute_reply.started":"2025-05-13T19:00:25.455365Z","shell.execute_reply":"2025-05-13T19:00:25.459941Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom gymnasium import Env\nfrom gymnasium.spaces import Box\n\nclass State:\n    def __init__(self, bars_count=30, verbose=False):\n        self.bars_count = bars_count\n        self._prices = None\n        self._offset = None\n        self.balance = None\n        self.trade_max_percentage = None\n        self.verbose = verbose\n        # These will be set in reset:\n        self.portfolio = None        # dict mapping currency -> amount (in native units)\n        self.base_currency = None\n        self.pairs = None            # list of tuples of currency pairs (sorted)\n        self.portfolio_currencies = None  # list of all currencies in portfolio (including base)\n        self.leverage = 15  # default leverage ratio\n\n    def reset(self, prices, offset, initial_balance, trade_max_percentage,\n              pairs, base_currency, portfolio_currencies):\n        # Ensure offset is high enough to allow for bars_count history.\n        assert offset >= self.bars_count - 1, \"Offset must allow for sufficient historical data\"\n        self._prices = prices.copy()\n        self._offset = offset\n        self.balance = initial_balance\n        self.trade_max_percentage = trade_max_percentage\n        self.base_currency = base_currency\n        self.pairs = pairs\n        self.portfolio_currencies = portfolio_currencies\n        # Initialize portfolio: all funds in base_currency; zero in others.\n        self.portfolio = {curr: (initial_balance if curr == base_currency else 0) \n                          for curr in portfolio_currencies}\n        self.ammortized_values = {curr: 0 for curr in portfolio_currencies}\n    def get_pair_price(self, row, pair):\n        return get_pair_price_from_row(row, pair, self.base_currency)\n\n    def encode(self):\n        \"\"\"\n        Build an observation dictionary that includes:\n          - 'past_prices': a float32 array of shape (bars_count, num_pairs) computed dynamically\n          - 'portfolio': a float32 array of portfolio fractions (computed in base currency)\n        \"\"\"\n        # Get the historical rows needed.\n        historical = self._prices.iloc[self._offset - self.bars_count + 1: self._offset + 1]\n        bars = self.bars_count\n        num_pairs = len(self.pairs)\n        past_prices = np.zeros((bars, num_pairs), dtype=np.float32)\n        # Compute price for each pair for every historical row.\n        for i, (_, row) in enumerate(historical.iterrows()):\n            for j, pair in enumerate(self.pairs):\n                past_prices[i, j] = self.get_pair_price(row, pair)\n        \n        # Compute current portfolio value in base currency using the latest row.\n        current_row = historical.iloc[-1]\n        total_value = 0.0\n        portfolio_values = {}\n        for curr, amt in self.portfolio.items():\n            if curr == self.base_currency:\n                val = amt\n            else:\n                val = amt / current_row[f\"{curr}{self.base_currency}\"]\n            portfolio_values[curr] = val\n            total_value += val\n        # Compute portfolio fractions in a fixed (sorted) order.\n        sorted_curr = sorted(self.portfolio.keys())\n        portfolio_frac = np.array([portfolio_values[c] for c in sorted_curr], dtype=np.float32)\n        portfolio_frac = portfolio_frac / (total_value + 1e-8)\n\n        # Add amortized values in sorted order, normalized (e.g., by total value)\n        amortized_vals = np.array([self.ammortized_values[c] for c in sorted_curr], dtype=np.float32)\n        # amortized_vals = amortized_vals / (total_value + 1e-8)  # normalize\n        \n        return {\"past_prices\": past_prices, \"portfolio\": portfolio_frac, \"amortized\": amortized_vals}\n        \n        # return {\"past_prices\": past_prices, \"portfolio\": portfolio_frac}\n\n    @property\n    def shape(self):\n        \"\"\"\n        Returns a dict mapping observation keys to their shapes.\n        \"\"\"\n        return {\n            \"past_prices\": (self.bars_count, len(self.pairs)),\n            \"portfolio\": (len(self.portfolio),),\n            \"amortized\": (len(self.ammortized_values),)\n        }\n\n    def step(self, action, reward_type=\"InDirect\"):\n        \"\"\"\n        Process a trade action vector (one action per pair). For each pair (A,B)\n        in self.pairs (sorted lexicographically), interpret a positive action as\n        \"buy A using B\" and a negative action as \"sell A for B.\" Trades are capped\n        by a maximum trade amount (based on current balance, leverage, and trade_max_percentage).\n        Returns the reward.\n        \"\"\"\n        reward = 0\n        current_row = self._prices.iloc[self._offset]\n        next_row = self._prices.iloc[self._offset + 1]\n        num_pairs = len(self.pairs)\n        # For each pair, compute a max trade amount (dividing available leverage across pairs)\n        per_pair_trade = self.balance * (self.leverage / num_pairs) * self.trade_max_percentage\n        # Loop over each pair and perform the trade.\n        for i, (A, B) in enumerate(self.pairs):\n            # if the action is negative, we swap the currencies\n            if action[i] < 0:\n                A, B = B, A\n            a_base_price = self.get_pair_price(current_row, (A, self.base_currency))\n            b_base_price = self.get_pair_price(current_row, (B, self.base_currency))\n            # Buy currency A using currency B.\n            trade_amount = per_pair_trade * abs(action[i])\n            trade_amount = min(trade_amount, trade_amount + (self.portfolio[B]/ b_base_price))\n            if trade_amount > 0:\n                # You spend trade_amount of B to get (trade_amount/price) of A.\n                self.portfolio[A] += trade_amount * a_base_price\n                self.portfolio[B] -= trade_amount * b_base_price\n                if reward_type ==\"InDirect\":\n                    if A == self.base_currency:\n                        if self.ammortized_values[B]>0 and self.portfolio[B]>0:\n                            reward += math.log(1 / ((self.ammortized_values[B]/self.portfolio[B]) * b_base_price))\n                        else:\n                            reward = 0\n                    self.ammortized_values[A] += trade_amount\n                    self.ammortized_values[B] -= trade_amount\n                if self.verbose:\n                    print(f\"{current_row['Timestamp']}: Spent {trade_amount* b_base_price:.2f} {B} to buy {trade_amount* a_base_price:.2f} {A}\")\n        # Compute new total portfolio value in base currency using next_row prices.\n        new_value = 0.0\n        for curr, amt in self.portfolio.items():\n            if curr == self.base_currency:\n                val = amt\n            else:\n                val = amt / next_row[f\"{curr}{self.base_currency}\"]\n            new_value += val\n        if(reward_type == \"Direct\"):\n            # Compute direct reward as the log return.\n            if new_value > 0 and self.balance > 0:\n                reward = math.log(new_value / self.balance)\n            else:\n                reward = 0\n        self.balance = new_value\n        self._offset += 1\n        done = self._offset >= len(self._prices) - 2\n        info = {\"balance\": self.balance, \"portfolio\": self.portfolio}\n        return reward, done, info","metadata":{"trusted":true,"id":"uduZuXbsgfJ5","execution":{"iopub.status.busy":"2025-05-13T19:00:25.461348Z","iopub.execute_input":"2025-05-13T19:00:25.461575Z","iopub.status.idle":"2025-05-13T19:00:27.927595Z","shell.execute_reply.started":"2025-05-13T19:00:25.461552Z","shell.execute_reply":"2025-05-13T19:00:27.926888Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n\nclass LSTMFeatureExtractor(BaseFeaturesExtractor):\n    def __init__(self, observation_space: dict, features_dim=128, lstm_hidden_size=64):\n        \"\"\"\n        observation_space: expects a Dict with keys:\n          - \"past_prices\": Tensor of shape (bars_count, num_pairs)\n          - \"portfolio\": Tensor of shape (portfolio_dim,)\n        features_dim: dimension of the final feature vector.\n        lstm_hidden_size: hidden state size for the LSTM processing the price sequence.\n        \"\"\"\n        super(LSTMFeatureExtractor, self).__init__(observation_space, features_dim)\n        \n        # Get shapes from the observation space.\n        self.bars_count, self.num_pairs = observation_space.spaces[\"past_prices\"].shape\n        self.portfolio_dim = observation_space.spaces[\"portfolio\"].shape[0]\n\n        # LSTM to process the price sequence.\n        self.lstm = nn.LSTM(\n            input_size=self.num_pairs,\n            hidden_size=lstm_hidden_size,\n            batch_first=True\n        )\n\n        # After computing indicators (RSI & MACD) for each pair, we have 2*num_pairs values.\n        self.indicator_dim = 2 * self.num_pairs\n\n        # Fully-connected layer to process portfolio info.\n        self.portfolio_fc = nn.Sequential(\n            nn.Linear(self.portfolio_dim, 32),\n            nn.ReLU()\n        )\n        \n        # Final fully-connected layer to combine all features.\n        # The input dimension is: lstm_hidden_size + indicator_dim + 32.\n        self.combined_fc = nn.Sequential(\n            nn.Linear(lstm_hidden_size + self.indicator_dim + 32, features_dim),\n            nn.ReLU()\n        )\n    def compute_ema(self, prices: th.Tensor, span: int) -> th.Tensor:\n        \"\"\"\n        Compute the exponential moving average (EMA) for the given prices.\n        prices: Tensor of shape (batch_size, bars_count, num_pairs)\n        span: period span for the EMA.\n        Returns:\n            A tensor of shape (batch_size, num_pairs) containing the final EMA value.\n        \"\"\"\n        alpha = 2.0 / (span + 1)\n        batch_size, T, num_pairs = prices.shape\n        # Initialize with the first time-step.\n        ema = prices[:, 0, :]  # shape: (batch_size, num_pairs)\n        # Iteratively update the EMA over time.\n        for t in range(1, T):\n            ema = alpha * prices[:, t, :] + (1 - alpha) * ema\n        return ema  # shape: (batch_size, num_pairs)\n\n    def compute_macd(self, prices: th.Tensor) -> th.Tensor:\n        \"\"\"\n        Compute the MACD (Moving Average Convergence Divergence) indicator.\n        Uses a short-term EMA (span 12) and a long-term EMA (span 26).\n        Returns:\n            A tensor of shape (batch_size, num_pairs) representing the MACD.\n        \"\"\"\n        ema_short = self.compute_ema(prices, span=12)\n        ema_long = self.compute_ema(prices, span=26)\n        macd = ema_short - ema_long\n        return macd\n\n    def compute_rsi(self, prices: th.Tensor, period: int = 14) -> th.Tensor:\n        \"\"\"\n        Compute the Relative Strength Index (RSI) using Wilder's smoothing method.\n        prices: Tensor of shape (batch_size, bars_count, num_pairs)\n        period: period for computing RSI (default: 14)\n        Returns:\n            A tensor of shape (batch_size, num_pairs) representing the RSI.\n        \"\"\"\n        # Compute differences along the time dimension.\n        diff = prices[:, 1:, :] - prices[:, :-1, :]  # shape: (batch_size, bars_count-1, num_pairs)\n        # Separate gains and losses.\n        gain = th.clamp(diff, min=0)\n        loss = -th.clamp(diff, max=0)\n        batch_size, T_minus_1, num_pairs = gain.shape\n        # Adjust period if the sequence is too short.\n        period = min(period, T_minus_1)\n        # Initialize the average gain and loss using the first 'period' values.\n        avg_gain = gain[:, :period, :].mean(dim=1)\n        avg_loss = loss[:, :period, :].mean(dim=1)\n        # Update the averages using Wilder's smoothing method.\n        for t in range(period, T_minus_1):\n            current_gain = gain[:, t, :]\n            current_loss = loss[:, t, :]\n            avg_gain = (avg_gain * (period - 1) + current_gain) / period\n            avg_loss = (avg_loss * (period - 1) + current_loss) / period\n        rs = avg_gain / (avg_loss + 1e-8)\n        rsi = 100 - (100 / (1 + rs))\n        return rsi\n\n    def forward(self, observations: dict) -> th.Tensor:\n        \"\"\"\n        observations: dict with keys \"past_prices\" and \"portfolio\"\n          - past_prices: Tensor of shape (batch_size, bars_count, num_pairs)\n          - portfolio: Tensor of shape (batch_size, portfolio_dim)\n        \"\"\"\n        past_prices = observations[\"past_prices\"]\n        # we pass price differences through the LSTM\n        price_diffs = past_prices[:, 1:, :] - past_prices[:, :-1, :]  # Shape: (batch_size, bars_count-1, num_pairs)\n        portfolio = observations[\"portfolio\"]\n\n        # Process the price sequence through the LSTM.\n        _, (h_n, _) = self.lstm(price_diffs)\n        lstm_last = h_n.squeeze(0)  # shape: (batch_size, lstm_hidden_size)\n\n        # Compute the technical indicators.\n        rsi = self.compute_rsi(past_prices, period=14)   # shape: (batch_size, num_pairs)\n        macd = self.compute_macd(past_prices)              # shape: (batch_size, num_pairs)\n        # Directly concatenate the raw indicator outputs.\n        indicators = th.cat([rsi, macd], dim=1)            # shape: (batch_size, 2*num_pairs)\n\n        # Process portfolio information.\n        portfolio_features = self.portfolio_fc(portfolio)\n\n        # Combine LSTM output, raw indicators, and portfolio features.\n        combined = th.cat([lstm_last, indicators, portfolio_features], dim=1)\n        return self.combined_fc(combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:00:27.928475Z","iopub.execute_input":"2025-05-13T19:00:27.928819Z","iopub.status.idle":"2025-05-13T19:00:42.631853Z","shell.execute_reply.started":"2025-05-13T19:00:27.928784Z","shell.execute_reply":"2025-05-13T19:00:42.631086Z"}},"outputs":[{"name":"stderr","text":"2025-05-13 19:00:30.728368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747162830.959074      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747162831.022724      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class ForexTradingEnv(Env):\n    def __init__(self, df, currencies=[\"EUR\",\"GBP\"], base_currency=\"USD\", initial_balance=1000,verbose=False,\n                 bars_count=30, max_steps=5000):\n        \"\"\"\n        df: pandas DataFrame containing price data. It is assumed to have columns like \"EURUSD\", \"GBPUSD\", etc.\n        currencies: list of non-base currencies (e.g. [\"EUR\",\"GBP\"]).\n        base_currency: the base currency (e.g. \"USD\").\n        \"\"\"\n        super(ForexTradingEnv, self).__init__()\n        self.df = df.copy()\n        self.initial_balance = initial_balance\n        self.bars_count = bars_count\n        self.max_steps = max_steps\n        self.steps = 0\n        self.base_currency = base_currency\n        self.currencies = currencies  # non-base currencies\n\n        # The portfolio will include the base and the other currencies.\n        self.portfolio_currencies = sorted(list(set([base_currency] + currencies)))\n\n        # Create all unique pairs from portfolio currencies.\n        # (For example, if portfolio currencies are [\"EUR\", \"GBP\", \"USD\"],\n        # the pairs will be: (\"EUR\",\"GBP\"), (\"EUR\",\"USD\"), (\"GBP\",\"USD\"))\n        pairs = []\n        for comb in combinations(self.portfolio_currencies, 2):\n            pair = tuple(sorted(comb))\n            pairs.append(pair)\n        pairs = sorted(pairs)\n        self.pairs = pairs\n\n        # Define the dynamic action space: one continuous action per pair.\n        self.action_space = Box(low=-1, high=1, shape=(len(self.pairs),), dtype=np.float32)\n\n        # Define the observation space as a Dict with two keys.\n        self.observation_space = Dict({\n            \"past_prices\": Box(low=0, high=np.inf, shape=(bars_count, len(self.pairs)), dtype=np.float32),\n            \"portfolio\": Box(low=0, high=1, shape=(len(self.portfolio_currencies),), dtype=np.float32)\n        })\n\n        self.state = State(bars_count=self.bars_count,verbose=verbose)\n\n    def seed(self, seed):\n        np.random.seed(seed)\n\n    def reset(self, seed=None):\n        super().reset(seed=seed)\n        self.steps = 0\n        rng = np.random.default_rng(seed)\n        # Choose an offset ensuring at least bars_count historical rows.\n        offset = rng.integers(self.bars_count - 1, len(self.df) - 1)\n        self.state.reset(prices=self.df, offset=offset,\n                         initial_balance=self.initial_balance,\n                         trade_max_percentage=0.2,\n                         pairs=self.pairs,\n                         base_currency=self.base_currency,\n                         portfolio_currencies=self.portfolio_currencies)\n        return self.state.encode(), {}\n\n    def step(self, action):\n        reward, terminated, info = self.state.step(action)\n        truncated = self.state._offset >= len(self.df) - 1\n        observation = self.state.encode()\n        self.steps += 1\n        if self.steps >= self.max_steps:\n            terminated = True\n        return observation, reward, terminated, truncated, info\n\n    def render(self, mode='human'):\n        if mode != 'human':\n            raise NotImplementedError(\"Only 'human' rendering mode is supported.\")\n        print(f\"Step: {self.state._offset}\")\n        print(f\"Portfolio: {self.state.portfolio}\")\n        print(f\"Balance: {self.state.balance}\")","metadata":{"trusted":true,"id":"CFr_DOcfgfJ6","execution":{"iopub.status.busy":"2025-05-13T19:00:42.632566Z","iopub.execute_input":"2025-05-13T19:00:42.633059Z","iopub.status.idle":"2025-05-13T19:00:42.644119Z","shell.execute_reply.started":"2025-05-13T19:00:42.633037Z","shell.execute_reply":"2025-05-13T19:00:42.643428Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport math\nfrom sb3_contrib import RecurrentPPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.vec_env import VecNormalize\nimport torch\nimport warnings\nimport zipfile\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Set up the Recurrent PPO model (with LSTM Policy)\ndata = get_forex_data()\nsplit_index = int(0.8 * len(data))\ntrain_data = data.iloc[:split_index]\ntest_data = data.iloc[split_index:]\n\nkwargs = {\"df\": train_data}\ntrain_envs = make_vec_env(ForexTradingEnv, n_envs=4, env_kwargs=kwargs)\ntrain_envs = VecNormalize(train_envs, norm_obs=True, norm_reward=True, clip_obs=10.0)\n\n# adding custom feature extractor\npolicy_kwargs = dict(\n    features_extractor_class=LSTMFeatureExtractor,\n    features_extractor_kwargs=dict(features_dim=256, lstm_hidden_size=128),\n    lstm_hidden_size=256,\n    n_lstm_layers=1,\n    shared_lstm=False,\n    enable_critic_lstm=True,\n)\n# model_load_path = '/kaggle/working/rppo_forex_indirect_v3.zip'\nmodel_save_path = \"rppo_forex_indirect_v3_2.zip\"  # Updated model path for R-PPO\n\nmodel_dir = '/kaggle/input/rppo_forex_indirect_v5_fixed/other/default/1'\nzip_path = '/kaggle/working/rppo_forex_indirect_v3_3.zip'\nlog_dir = \"rppo_logs/\"\n\ndef zip_model_directory(directory_path, zip_path):\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(directory_path):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, start=directory_path)\n                zipf.write(file_path, arcname)\n\nzip_model_directory(model_dir, zip_path)\nprint(f\"Zipped model saved to {zip_path}\")\n\n# Load the existing model if it exists, otherwise create a new one\nif os.path.exists(zip_path):\n    print(f\"Loading existing model from {zip_path}...\")\n    model = RecurrentPPO.load(zip_path, env=train_envs, device=device, tensorboard_log=log_dir)\nelse:\n    print(\"No existing model found. Training from scratch...\")\n    model = RecurrentPPO(\n        \"MlpLstmPolicy\", \n        train_envs, \n        tensorboard_log=log_dir,\n        verbose=1, \n        device=device, \n        policy_kwargs=policy_kwargs,\n        n_steps=256) \n\n# Train the model\n# try:\n#     model.learn(total_timesteps=3000000) #10000000 \n# except KeyboardInterrupt:\n#     model.save(model_save_path)\n#     print(f\"Training interrupted. Model saved to {model_save_path}\")\n\n# Save the model after training\nmodel.save(model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true,"id":"fRjJ70_QgfJ7","outputId":"809b16b5-5f61-47d2-aaca-8104c4c3a8ff","execution":{"iopub.status.busy":"2025-05-13T19:00:42.644968Z","iopub.execute_input":"2025-05-13T19:00:42.645307Z","iopub.status.idle":"2025-05-13T19:00:47.441552Z","shell.execute_reply.started":"2025-05-13T19:00:42.645283Z","shell.execute_reply":"2025-05-13T19:00:47.440782Z"}},"outputs":[{"name":"stdout","text":"Zipped model saved to /kaggle/working/rppo_forex_indirect_v3_3.zip\nLoading existing model from /kaggle/working/rppo_forex_indirect_v3_3.zip...\nModel saved to rppo_forex_indirect_v3_2.zip\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# def calculate_performance_metrics(balance_history, trading_days=252):\n#     balance = np.array(balance_history)\n#     # Avoid division by zero or empty arrays\n#     if len(balance) < 2:\n#         return {}\n#     returns = np.diff(balance) / balance[:-1]\n#     total_return = balance[-1] / balance[0] - 1\n    \n#     # Annualized return using the formula: (final/initial)^(trading_days/num_periods) - 1\n#     annualized_return = (balance[-1] / balance[0]) ** (trading_days / len(returns)) - 1\n#     # Daily volatility (standard deviation of returns)\n#     daily_vol = np.std(returns)\n#     # Sharpe ratio (assuming risk-free rate = 0)\n#     sharpe_ratio = np.mean(returns) / daily_vol * np.sqrt(trading_days) if daily_vol != 0 else np.nan\n    \n#     # Maximum drawdown: max loss from a peak to a trough\n#     cumulative_max = np.maximum.accumulate(balance)\n#     drawdowns = (balance - cumulative_max) / cumulative_max\n#     max_drawdown = np.min(drawdowns)\n    \n#     # Sortino ratio: similar to Sharpe but considers only downside risk\n#     negative_returns = returns[returns < 0]\n#     downside_std = np.std(negative_returns) if negative_returns.size > 0 else 0\n#     sortino_ratio = np.mean(returns) / downside_std * np.sqrt(trading_days) if downside_std != 0 else np.nan\n#     return {\n#         \"Total Return\": total_return,\n#         \"Annualized Return\": annualized_return,\n#         \"Daily Volatility\": daily_vol,\n#         \"Sharpe Ratio\": sharpe_ratio,\n#         \"Max Drawdown\": max_drawdown,\n#         \"Sortino Ratio\": sortino_ratio,\n#     }\n\n# import numpy as np\n\ndef calculate_performance_metrics(balance_history, trading_hours_per_year=8760):\n    balance = np.array(balance_history)\n    \n    # Avoid division by zero or empty arrays\n    if len(balance) < 2:\n        return {}\n    \n    # Hourly returns\n    returns = np.diff(balance) / balance[:-1]\n    total_return = balance[-1] / balance[0] - 1\n\n    # Annualized return based on hourly compounding\n    annualized_return = (balance[-1] / balance[0]) ** (trading_hours_per_year / len(returns)) - 1\n    \n    # Hourly volatility (standard deviation of returns)\n    hourly_vol = np.std(returns)\n    \n    # Sharpe ratio (assuming risk-free rate = 0)\n    sharpe_ratio = np.mean(returns) / hourly_vol * np.sqrt(trading_hours_per_year) if hourly_vol != 0 else np.nan\n    \n    # Maximum drawdown\n    cumulative_max = np.maximum.accumulate(balance)\n    drawdowns = (balance - cumulative_max) / cumulative_max\n    max_drawdown = np.min(drawdowns)\n    \n    # Sortino ratio (using only downside risk)\n    negative_returns = returns[returns < 0]\n    downside_std = np.std(negative_returns) if negative_returns.size > 0 else 0\n    sortino_ratio = np.mean(returns) / downside_std * np.sqrt(trading_hours_per_year) if downside_std != 0 else np.nan\n    \n    return {\n        \"Total Return\": total_return,\n        \"Annualized Return\": annualized_return,\n        \"Daily Volatility\": hourly_vol,\n        \"Sharpe Ratio\": sharpe_ratio,\n        \"Max Drawdown\": max_drawdown,\n        \"Sortino Ratio\": sortino_ratio,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:00:47.442297Z","iopub.execute_input":"2025-05-13T19:00:47.442820Z","iopub.status.idle":"2025-05-13T19:00:47.449926Z","shell.execute_reply.started":"2025-05-13T19:00:47.442792Z","shell.execute_reply":"2025-05-13T19:00:47.449054Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom stable_baselines3.common.vec_env import VecNormalize\nfrom stable_baselines3.common.env_util import make_vec_env\nimport plotly.graph_objects as go\n\n# Storage for all accepted performance metrics\nall_metrics = []\nrequired_envs = 1000\nbatch_size = 50\nmin_steps = 200\n\nwhile len(all_metrics) < required_envs:\n    # Step 1: Create environments\n    test_kwargs = {\n        \"df\": data,\n        \"max_steps\": 5000,\n        \"verbose\": False\n    }\n    test_envs = make_vec_env(ForexTradingEnv, n_envs=batch_size, env_kwargs=test_kwargs)\n    test_envs = VecNormalize(test_envs, norm_obs=True, norm_reward=True, clip_obs=10.0)\n    obs = test_envs.reset()\n\n    # Step 2: Setup state and history\n    lstm_states = None\n    episode_starts = np.ones((test_envs.num_envs,), dtype=bool)\n    portfolio_history = [{\"Balance\": []} for _ in range(test_envs.num_envs)]\n\n    # Step 3: Run environments until one terminates\n    while True:\n        action, lstm_states = model.predict(\n            obs, state=lstm_states, episode_start=episode_starts, deterministic=True\n        )\n        obs, rewards, dones, infos = test_envs.step(action)\n\n        for i, info in enumerate(infos):\n            portfolio_history[i][\"Balance\"].append(info[\"balance\"])\n\n        episode_starts = dones\n        if dones.any():\n            break\n\n    # Step 4: Validate step count\n    steps_per_env = [len(ph[\"Balance\"]) for ph in portfolio_history]\n    if min(steps_per_env) < min_steps:\n        print(\"Batch rejected due to short run.\")\n        continue\n\n    print(f\"Batch accepted: {len(all_metrics)} + {batch_size} envs\")\n\n    # Step 5: Compute and store metrics\n    for i in range(batch_size):\n        metrics = calculate_performance_metrics(portfolio_history[i][\"Balance\"])\n        all_metrics.append(metrics)\n\n# Step 6: Compute percentile statistics\ndef percentile_summary(metrics_list, metric_key, percentiles=[25, 50, 75, 90]):\n    values = [m[metric_key] for m in metrics_list]\n    return np.percentile(values, percentiles).tolist()\n\nmetric_keys = [\n    \"Total Return\", \"Annualized Return\", \"Daily Volatility\",\n    \"Sharpe Ratio\", \"Max Drawdown\", \"Sortino Ratio\"\n]\n\ntable_data = {\n    \"Metric\": [],\n    \"25th Percentile\": [],\n    \"50th Percentile (Median)\": [],\n    \"75th Percentile\": [],\n    \"90th Percentile\": []\n}\n\nfor key in metric_keys:\n    ps = percentile_summary(all_metrics, key)\n    table_data[\"Metric\"].append(key)\n    table_data[\"25th Percentile\"].append(f\"{ps[0]*100:.2f}%\" if \"Return\" in key or \"Drawdown\" in key else f\"{ps[0]:.2f}\")\n    table_data[\"50th Percentile (Median)\"].append(f\"{ps[1]*100:.2f}%\" if \"Return\" in key or \"Drawdown\" in key else f\"{ps[1]:.2f}\")\n    table_data[\"75th Percentile\"].append(f\"{ps[2]*100:.2f}%\" if \"Return\" in key or \"Drawdown\" in key else f\"{ps[2]:.2f}\")\n    table_data[\"90th Percentile\"].append(f\"{ps[3]*100:.2f}%\" if \"Return\" in key or \"Drawdown\" in key else f\"{ps[3]:.2f}\")\n\n# Step 7: Plot percentile summary as a table\nsummary_table = go.Figure(data=[go.Table(\n    header=dict(\n        values=list(table_data.keys()),\n        fill_color='paleturquoise',\n        align='left'\n    ),\n    cells=dict(\n        values=list(table_data.values()),\n        fill_color='lavender',\n        align='left'\n    )\n)])\nsummary_table.update_layout(\n    title = f\"Performance Metrics Percentile Summary (n={required_envs})\",\n    margin=dict(l=20, r=20, t=50, b=20)\n)\nsummary_table.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:00:47.452431Z","iopub.execute_input":"2025-05-13T19:00:47.453102Z","iopub.status.idle":"2025-05-13T20:10:37.171483Z","shell.execute_reply.started":"2025-05-13T19:00:47.453078Z","shell.execute_reply":"2025-05-13T20:10:37.170634Z"}},"outputs":[{"name":"stdout","text":"Batch accepted: 0 + 50 envs\nBatch accepted: 50 + 50 envs\nBatch accepted: 100 + 50 envs\nBatch rejected due to short run.\nBatch accepted: 150 + 50 envs\nBatch accepted: 200 + 50 envs\nBatch accepted: 250 + 50 envs\nBatch accepted: 300 + 50 envs\nBatch accepted: 350 + 50 envs\nBatch accepted: 400 + 50 envs\nBatch accepted: 450 + 50 envs\nBatch rejected due to short run.\nBatch accepted: 500 + 50 envs\nBatch accepted: 550 + 50 envs\nBatch accepted: 600 + 50 envs\nBatch accepted: 650 + 50 envs\nBatch rejected due to short run.\nBatch accepted: 700 + 50 envs\nBatch accepted: 750 + 50 envs\nBatch accepted: 800 + 50 envs\nBatch accepted: 850 + 50 envs\nBatch accepted: 900 + 50 envs\nBatch accepted: 950 + 50 envs\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_altair.py:16: DeprecationWarning:\n\nthe imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c238deb7-994f-4aa5-9f82-002b6718b703\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c238deb7-994f-4aa5-9f82-002b6718b703\")) {                    Plotly.newPlot(                        \"c238deb7-994f-4aa5-9f82-002b6718b703\",                        [{\"cells\":{\"align\":\"left\",\"fill\":{\"color\":\"lavender\"},\"values\":[[\"Total Return\",\"Annualized Return\",\"Daily Volatility\",\"Sharpe Ratio\",\"Max Drawdown\",\"Sortino Ratio\"],[\"-4.49%\",\"-25.20%\",\"0.00\",\"-1.63\",\"-11.66%\",\"-2.17\"],[\"-0.12%\",\"-0.33%\",\"0.00\",\"0.06\",\"-7.48%\",\"0.08\"],[\"4.90%\",\"34.01%\",\"0.00\",\"1.77\",\"-4.90%\",\"2.51\"],[\"10.38%\",\"93.67%\",\"0.00\",\"3.52\",\"-3.09%\",\"5.18\"]]},\"header\":{\"align\":\"left\",\"fill\":{\"color\":\"paleturquoise\"},\"values\":[\"Metric\",\"25th Percentile\",\"50th Percentile (Median)\",\"75th Percentile\",\"90th Percentile\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":20,\"r\":20,\"t\":50,\"b\":20},\"title\":{\"text\":\"Performance Metrics Percentile Summary (n=1000)\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c238deb7-994f-4aa5-9f82-002b6718b703');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# test_kwargs = {\n#     \"df\": data,\n#     \"max_steps\": 5000,\n#     \"verbose\": False\n# }\n\n# # Create the vectorized environment using the dynamic kwargs.\n# test_envs = make_vec_env(ForexTradingEnv, n_envs=50, env_kwargs=test_kwargs)\n# test_envs = VecNormalize(test_envs, norm_obs=True, norm_reward=True, clip_obs=10.0)\n# obs = test_envs.reset()\n\n# # Dynamically determine the portfolio keys from the first environment.\n# env0 = test_envs.envs[0].unwrapped\n# portfolio_keys = sorted(list(env0.state.portfolio.keys()))\n# # Optionally, add a key for overall balance.\n# portfolio_keys.append(\"Balance\")\n\n# # Initialize portfolio history for each environment.\n# portfolio_history = [{key: [] for key in portfolio_keys} for _ in range(test_envs.num_envs)]\n\n# # Initialize LSTM states and episode start signals.\n# lstm_states = None\n# episode_starts = np.ones((test_envs.num_envs,), dtype=bool)\n\n# # Main evaluation loop.\n# while True:\n#     # Get the predicted action from the model.\n#     action, lstm_states = model.predict(\n#         obs, state=lstm_states, episode_start=episode_starts, deterministic=True\n#     )\n\n#     # Step the environment.\n#     obs, rewards, dones, infos = test_envs.step(action)\n\n#     # Record portfolio values for each environment dynamically.\n#     for i, info in enumerate(infos):\n#         portfolio = info[\"portfolio\"]\n#         for key in portfolio_history[i].keys():\n#             if key == \"Balance\":\n#                 portfolio_history[i][key].append(info[\"balance\"])\n#             else:\n#                 portfolio_history[i][key].append(portfolio.get(key, 0))\n\n#     # Update episode start signals (reset LSTM states for new episodes).\n#     episode_starts = dones\n\n#     # Break out when any episode is done.\n#     if dones.any():\n#         break\n\n# print(\"Evaluation complete!\")\n","metadata":{"trusted":true,"id":"bMmch9l9gfJ9","outputId":"7a5c35c9-2344-498b-f88d-e42eec496598","execution":{"iopub.status.busy":"2025-05-13T20:10:37.172551Z","iopub.execute_input":"2025-05-13T20:10:37.173292Z","iopub.status.idle":"2025-05-13T20:10:37.177483Z","shell.execute_reply.started":"2025-05-13T20:10:37.173266Z","shell.execute_reply":"2025-05-13T20:10:37.176673Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# import plotly.graph_objects as go\n# import numpy as np\n\n# # List to collect summary metrics for each environment\n# summary_metrics = []\n\n# # Loop over environments and plot individual figures with metrics annotations\n# for i in range(test_envs.num_envs):\n#     balance_history = portfolio_history[i][\"Balance\"]\n#     metrics = calculate_performance_metrics(balance_history)\n    \n#     # Add environment identifier to the metrics dictionary\n#     metrics['Environment'] = f\"Env {i + 1}\"\n#     summary_metrics.append(metrics)\n# table_headers = [\n#     \"Environment\", \"Total Return\", \"Annualized Return\", \n#     \"Daily Volatility\", \"Sharpe Ratio\", \"Max Drawdown\", \n#     \"Sortino Ratio\"\n# ]\n\n# # Prepare lists for each column\n# envs = []\n# total_returns = []\n# annualized_returns = []\n# daily_vols = []\n# sharpe_ratios = []\n# max_drawdowns = []\n# sortino_ratios = []\n\n\n# for met in summary_metrics:\n#     envs.append(met.get(\"Environment\", \"\"))\n#     total_returns.append(met.get(\"Total Return\", 0))\n#     annualized_returns.append(met.get(\"Annualized Return\", 0))\n#     daily_vols.append(met.get(\"Daily Volatility\", 0))\n#     sharpe_ratios.append(met.get(\"Sharpe Ratio\", 0))\n#     max_drawdowns.append(met.get(\"Max Drawdown\", 0))\n#     sortino_ratios.append(met.get(\"Sortino Ratio\", 0))\n\n# avg_total_return = np.mean(total_returns)\n# avg_annualized_return = np.mean(annualized_returns)\n# avg_daily_vol = np.mean(daily_vols)\n# avg_sharpe_ratio = np.mean(sharpe_ratios)\n# avg_max_drawdown = np.mean(max_drawdowns)\n# avg_sortino_ratio = np.mean(sortino_ratios)\n\n# # Format values as strings with correct number formatting\n# total_returns = [f\"{x*100:.2f}%\" for x in total_returns] + [f\"{avg_total_return*100:.2f}%\"]\n# annualized_returns = [f\"{x*100:.2f}%\" for x in annualized_returns] + [f\"{avg_annualized_return*100:.2f}%\"]\n# daily_vols = [f\"{x*100:.2f}%\" for x in daily_vols] + [f\"{avg_daily_vol*100:.2f}%\"]\n# sharpe_ratios = [f\"{x:.2f}\" for x in sharpe_ratios] + [f\"{avg_sharpe_ratio:.2f}\"]\n# max_drawdowns = [f\"{x*100:.2f}%\" for x in max_drawdowns] + [f\"{avg_max_drawdown*100:.2f}%\"]\n# sortino_ratios = [f\"{x:.2f}\" for x in sortino_ratios] + [f\"{avg_sortino_ratio:.2f}\"]\n\n# # Append \"Average\" row at the end\n# envs.append(\"Average\")\n\n# # Create a Plotly Table for summary statistics\n# summary_table = go.Figure(data=[go.Table(\n#     header=dict(\n#         values=table_headers,\n#         fill_color='paleturquoise',\n#         align='left',\n#         font=dict(size=12)\n#     ),\n#     cells=dict(\n#         values=[\n#             envs, total_returns, annualized_returns, \n#             daily_vols, sharpe_ratios, max_drawdowns, sortino_ratios\n#         ],\n#         fill_color='lavender',\n#         align='left',\n#         font=dict(size=11)\n#     ))\n# ])\n\n# summary_table.update_layout(\n#     title=\"Summary Performance Metrics Across Environments\",\n#     margin=dict(l=20, r=20, t=50, b=20)\n# )\n\n# summary_table.show()\n\n# bal = go.Figure()\n# for i in range(test_envs.num_envs):\n#     bal.add_trace(go.Scatter(y=portfolio_history[i][\"Balance\"], mode=\"lines\", name=f\"Env {i}\",))\n# bal.update_layout(\n#         title=f\"Blance Progression\",\n#         xaxis_title=\"Steps\",\n#         yaxis_title=\"Portfolio Value\",\n#         hovermode=\"x unified\",\n#     )\n# bal.show()\n# for i in range(test_envs.num_envs):\n#     fig = go.Figure()\n#     for key in portfolio_history[i].keys():\n#         if key == 'Environment':\n#             continue\n#         fig.add_trace(go.Scatter(y=portfolio_history[i][key], mode=\"lines\", name=key))\n#     # Set legend position to the right\n#     fig.update_layout(legend=dict(x=1.05, y=1))\n\n#     # Create annotations for performance metrics, placed on the right, below the legend\n#     annotations = []\n#     y_pos = 0.7  # Starting y-position for metrics annotations\n#     for key, value in summary_metrics[i].items():\n#         if key == \"Environment\":\n#             continue  # Skip environment name in annotations\n\n#         # Format as percentage if key contains 'Return' or 'Drawdown'\n#         text = f\"{key}: {value:.2%}\" if \"Return\" in key or \"Drawdown\" in key else f\"{key}: {value:.2f}\"\n#         annotations.append(dict(\n#             xref=\"paper\", yref=\"paper\",\n#             x=1.0, y=y_pos,  # Position to the right of the plot\n#             xanchor=\"left\", yanchor=\"top\",\n#             text=text,\n#             showarrow=False,\n#             font=dict(size=10),\n#             align=\"left\"\n#         ))\n#         y_pos -= 0.05  # Adjust vertical spacing for next metric\n\n#     fig.update_layout(\n#         title=f\"Portfolio Progression in Environment {i + 1}\",\n#         xaxis_title=\"Steps\",\n#         yaxis_title=\"Portfolio Value\",\n#         hovermode=\"x unified\",\n#         annotations=annotations\n#     )\n\n#     fig.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:10:37.178466Z","iopub.execute_input":"2025-05-13T20:10:37.178822Z","iopub.status.idle":"2025-05-13T20:10:37.198448Z","shell.execute_reply.started":"2025-05-13T20:10:37.178798Z","shell.execute_reply":"2025-05-13T20:10:37.197899Z"}},"outputs":[],"execution_count":11}]}