{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T09:03:48.062381Z",
     "iopub.status.busy": "2025-01-13T09:03:48.062103Z",
     "iopub.status.idle": "2025-01-13T09:03:54.083194Z",
     "shell.execute_reply": "2025-01-13T09:03:54.082303Z",
     "shell.execute_reply.started": "2025-01-13T09:03:48.062348Z"
    },
    "id": "ZXE-41IRsN9v",
    "outputId": "74349d41-8b9e-4853-b9db-34a8007c07d4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sb3-contrib torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T09:03:54.084679Z",
     "iopub.status.busy": "2025-01-13T09:03:54.084363Z",
     "iopub.status.idle": "2025-01-13T09:04:05.406877Z",
     "shell.execute_reply": "2025-01-13T09:04:05.406228Z",
     "shell.execute_reply.started": "2025-01-13T09:03:54.084650Z"
    },
    "id": "Pcfwg0mssN9w",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T09:04:05.408212Z",
     "iopub.status.busy": "2025-01-13T09:04:05.407640Z",
     "iopub.status.idle": "2025-01-13T09:04:05.413161Z",
     "shell.execute_reply": "2025-01-13T09:04:05.412182Z",
     "shell.execute_reply.started": "2025-01-13T09:04:05.408187Z"
    },
    "id": "otisKEAnsN9w",
    "outputId": "1a0d4694-0078-4163-a5e1-64226283effb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def get_forex_data():\n",
    "    # Load the dataset\n",
    "    data_set = pd.read_csv('/kaggle/input/foreign-exchange-rates/Foreign_Exchange_Rates.csv', na_values='ND')\n",
    "\n",
    "    # Interpolate missing values to handle missing data\n",
    "    data_set = data_set.infer_objects(copy=False)  # Ensure non-numeric columns are correctly inferred\n",
    "    data_set.interpolate(inplace=True)\n",
    "\n",
    "    # Select only the columns for EUR/USD and JPY/USD exchange rates\n",
    "    df = data_set[['EURO AREA - EURO/US$', 'JAPAN - YEN/US$']].copy()\n",
    "\n",
    "    # Add derived column for YEN/EURO exchange rate\n",
    "    df['YEN/EURO'] = df['JAPAN - YEN/US$'] / df['EURO AREA - EURO/US$']\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T09:04:05.415122Z",
     "iopub.status.busy": "2025-01-13T09:04:05.414916Z",
     "iopub.status.idle": "2025-01-13T09:04:05.436717Z",
     "shell.execute_reply": "2025-01-13T09:04:05.436075Z",
     "shell.execute_reply.started": "2025-01-13T09:04:05.415104Z"
    },
    "id": "OLwUSxFGsN9w",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import math\n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self):\n",
    "        self._prices = None\n",
    "        self._first_diff = None\n",
    "        self._offset = None\n",
    "        self.balance = None\n",
    "        self.portfolio = None\n",
    "        self.euro_buy_value = None\n",
    "        self.yen_buy_value = None\n",
    "        self.trade_max_percentage = None\n",
    "\n",
    "    def reset(self, prices, offset, initial_balance, trade_max_percentage ):\n",
    "        self._prices = prices\n",
    "        first_differences = prices.diff()\n",
    "        # Normalize the first differences using Min-Max normalization\n",
    "        self._first_diff =  (first_differences - first_differences.min()) / (first_differences.max() - first_differences.min())\n",
    "        self._offset = offset\n",
    "        self.balance = initial_balance\n",
    "        self.trade_max_percentage = trade_max_percentage\n",
    "        self.portfolio = {'USD': initial_balance, 'EUR': 0, 'JPY':0}\n",
    "        self.euro_buy_value = 0\n",
    "        self.yen_buy_value = 0\n",
    "\n",
    "    def step(self, action, reward_type = \"inDirect\"):\n",
    "        reward = 0\n",
    "        current_price = self._prices.iloc[self._offset][['EURO AREA - EURO/US$', 'JAPAN - YEN/US$', 'YEN/EURO']].values\n",
    "        eur_usd, jpy_usd, jpy_eur = current_price\n",
    "        max_trade_amount = self.balance * self.trade_max_percentage\n",
    "        # action is an array of floats between -1 and 1\n",
    "        # remove the looping transaction\n",
    "        if(action[0] < 0 and action[1] > 0 and action[2] < 0):\n",
    "            common = min(-action[0], action[1], -action[2])\n",
    "            action[0] += common\n",
    "            action[1] -= common\n",
    "            action[2] += common\n",
    "        elif(action[0] > 0 and action[1] < 0 and action[2] > 0):\n",
    "            common = min(action[0], -action[1], action[2])\n",
    "            action[0] -= common\n",
    "            action[1] += common\n",
    "            action[2] -= common\n",
    "        # USD and EUR, positive means buy EUR\n",
    "        if action[0] > 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[0])\n",
    "            trade_volume = min(self.portfolio['USD'], trade_amount)\n",
    "            reward = 0\n",
    "\n",
    "            self.portfolio['EUR'] += trade_volume * eur_usd\n",
    "            self.portfolio['USD'] -= trade_volume\n",
    "            self.euro_buy_value += trade_volume\n",
    "        elif action[0] < 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[0])\n",
    "            trade_volume = min(self.portfolio['EUR'], trade_amount * eur_usd)\n",
    "            if trade_volume > 0:\n",
    "                reward = trade_volume * (1/eur_usd-(self.euro_buy_value/self.portfolio['EUR']))\n",
    "            self.portfolio['USD'] += trade_volume / eur_usd\n",
    "            self.portfolio['EUR'] -= trade_volume\n",
    "            self.euro_buy_value -= trade_volume / eur_usd\n",
    "        # USD and YEN, positive means buy YEN\n",
    "        if action[1] > 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[1])\n",
    "            trade_volume = min(self.portfolio['USD'], trade_amount)\n",
    "            reward = 0\n",
    "            self.portfolio['JPY'] += trade_volume * jpy_usd\n",
    "            self.portfolio['USD'] -= trade_volume\n",
    "            self.yen_buy_value += trade_volume\n",
    "        elif action[1] < 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[1])\n",
    "            trade_volume = min(self.portfolio['JPY'], trade_amount * jpy_usd)\n",
    "            if trade_volume > 0:\n",
    "                reward = trade_volume * (1/jpy_usd - self.yen_buy_value/self.portfolio['JPY'])\n",
    "            self.portfolio['USD'] += trade_volume / jpy_usd\n",
    "            self.portfolio['JPY'] -= trade_volume\n",
    "            self.yen_buy_value -= trade_volume / jpy_usd\n",
    "        # EUR and YEN, positive means buy YEN\n",
    "        if action[2] > 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[2])\n",
    "            trade_volume = min(self.portfolio['EUR'], trade_amount * eur_usd)\n",
    "            if trade_volume > 0:\n",
    "                reward = trade_volume * (1/eur_usd - self.euro_buy_value/self.portfolio['EUR'])\n",
    "\n",
    "            self.portfolio['JPY'] += trade_volume * jpy_eur\n",
    "            self.portfolio['EUR'] -= trade_volume\n",
    "            self.euro_buy_value -= trade_volume / eur_usd\n",
    "            self.yen_buy_value += trade_volume / eur_usd\n",
    "        elif action[2] < 0:\n",
    "            trade_amount =  abs(max_trade_amount*action[2])\n",
    "            trade_volume = min(self.portfolio['JPY'], trade_amount * jpy_usd)\n",
    "            if trade_volume > 0:\n",
    "                reward = trade_volume * (1/jpy_usd - self.yen_buy_value/self.portfolio['JPY'])\n",
    "\n",
    "            self.portfolio['EUR'] += trade_volume / jpy_eur\n",
    "            self.portfolio['JPY'] -= trade_volume\n",
    "            self.euro_buy_value += trade_volume / jpy_usd\n",
    "            self.yen_buy_value -= trade_volume / jpy_usd\n",
    "\n",
    "        portfolio_value = (self.portfolio['USD'] + self.portfolio['EUR'] / eur_usd + self.portfolio['JPY'] / jpy_usd)\n",
    "        if reward_type == \"Direct\":\n",
    "            reward = portfolio_value - self.balance\n",
    "        self.balance = portfolio_value\n",
    "        self._offset += 1\n",
    "        done = self._offset >= len(self._prices) - 1\n",
    "        # reward = 100*(action[0]-action[1]-action[2])\n",
    "        return reward, done\n",
    "\n",
    "    def encode(self):\n",
    "        # Extract historical prices\n",
    "        current_prices = self._first_diff.iloc[self._offset]\n",
    "        encoded_prices = np.array(current_prices[['EURO AREA - EURO/US$', 'JAPAN - YEN/US$', 'YEN/EURO']]).flatten()\n",
    "        portfolio_fraction = np.array([self.portfolio['USD'],self.portfolio['EUR'],self.portfolio['JPY']])/self.balance\n",
    "\n",
    "\n",
    "        # Combine all features into a single array\n",
    "        # use log to normalize balance\n",
    "        encoded_features = np.concatenate([\n",
    "            encoded_prices,\n",
    "            portfolio_fraction,\n",
    "            [self.euro_buy_value, self.yen_buy_value/100, self.trade_max_percentage]\n",
    "        ])\n",
    "        return encoded_features\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        # Update the shape to match the new number of encoded features\n",
    "        return (3 + 3 + 3,)  # 3 prices + 3 portfolio + 3 additional values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T09:04:05.438003Z",
     "iopub.status.busy": "2025-01-13T09:04:05.437731Z",
     "iopub.status.idle": "2025-01-13T09:04:05.457874Z",
     "shell.execute_reply": "2025-01-13T09:04:05.457067Z",
     "shell.execute_reply.started": "2025-01-13T09:04:05.437983Z"
    },
    "id": "9YxccNfDsN9x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ForexTradingEnv(Env):\n",
    "    def __init__(self, df, initial_balance=1000):\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.initial_balance = initial_balance\n",
    "        self.state = State()\n",
    "        # shape is all the currency combinations\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(3,), dtype=np.float32)\n",
    "        self.observation_space = Box(\n",
    "            low=0, high=np.inf, shape=self.state.shape, dtype=np.float32\n",
    "        )\n",
    "    def seed(self, seed):\n",
    "        np.random.seed(seed)\n",
    "    def reset(self,sequence_length, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        offset = np.random.randint(sequence_length, len(self.df) - 1)\n",
    "        print(offset)\n",
    "        self.state.reset(prices=self.df, offset=offset, initial_balance=self.initial_balance, trade_max_percentage= 1)\n",
    "        return self.state.encode()\n",
    "\n",
    "    def step(self, action):\n",
    "        reward, terminated = self.state.step(action)\n",
    "        truncated = self.state._offset >= len(self.df) - 1\n",
    "        observation = self.state.encode()\n",
    "        info = {\n",
    "            \"balance\": self.state.balance,  # Include the current balance\n",
    "            # Add any other relevant fields from the State object if needed\n",
    "        }\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if mode != 'human':\n",
    "            raise NotImplementedError(\"Only 'human' rendering mode is supported.\")\n",
    "        print(f\"Step: {self.state._offset}\")\n",
    "        print(f\"Portfolio: {self.state.portfolio}\")\n",
    "        print(f\"Balance: {self.state.balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T09:04:05.458725Z",
     "iopub.status.busy": "2025-01-13T09:04:05.458547Z",
     "iopub.status.idle": "2025-01-13T09:04:05.477556Z",
     "shell.execute_reply": "2025-01-13T09:04:05.476726Z",
     "shell.execute_reply.started": "2025-01-13T09:04:05.458709Z"
    },
    "id": "zJzzXK80sN9x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SequenceEnvironment(gym.Env):\n",
    "    def __init__(self, df, sequence_length):\n",
    "        super(SequenceEnvironment, self).__init__()\n",
    "        self.original_env = ForexTradingEnv(df)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.buffer = []\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.repeat(self.original_env.observation_space.low[None, :], sequence_length, axis=0),\n",
    "            high=np.repeat(self.original_env.observation_space.high[None, :], sequence_length, axis=0),\n",
    "            dtype=self.original_env.observation_space.dtype\n",
    "        )\n",
    "        self.action_space = self.original_env.action_space\n",
    "\n",
    "    def reset(self,seed=None):\n",
    "        obs = self.original_env.reset(self.sequence_length)\n",
    "        self.buffer = [obs] * self.sequence_length\n",
    "        return np.array(self.buffer), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.original_env.step(action)\n",
    "        self.buffer.pop(0)\n",
    "        self.buffer.append(obs)\n",
    "        return np.array(self.buffer), reward, terminated, truncated, info\n",
    "        \n",
    "    def get_balance(self):\n",
    "        return self.original_env.state.balance\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T09:04:05.478569Z",
     "iopub.status.busy": "2025-01-13T09:04:05.478306Z",
     "iopub.status.idle": "2025-01-13T09:04:05.497371Z",
     "shell.execute_reply": "2025-01-13T09:04:05.496519Z",
     "shell.execute_reply.started": "2025-01-13T09:04:05.478549Z"
    },
    "id": "xHZ_qvMhsN9x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from gymnasium import spaces\n",
    "\n",
    "class LSTMFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256, lstm_hidden_size: int = 128):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "\n",
    "        # Extract input size from observation space\n",
    "        self.sequence_length, self.num_features = observation_space.shape\n",
    "\n",
    "        # Define LSTM\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, hidden_size=lstm_hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Linear layers for feature extraction\n",
    "        self.linear1 = nn.Linear(lstm_hidden_size, 128)\n",
    "        self.linear2 = nn.Linear(128, features_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        # Initialize LSTM hidden and cell states\n",
    "        batch_size = observations.size(0)\n",
    "        h_0 = th.zeros(1, batch_size, self.lstm_hidden_size).to(observations.device)\n",
    "        c_0 = th.zeros(1, batch_size, self.lstm_hidden_size).to(observations.device)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(observations, (h_0, c_0))\n",
    "\n",
    "        # Use the output of the last time step\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "\n",
    "        # Pass through linear layers\n",
    "        x = self.activation(self.linear1(last_time_step_out))\n",
    "        features = self.activation(self.linear2(x))\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T09:18:08.297824Z",
     "iopub.status.busy": "2025-01-13T09:18:08.297524Z",
     "iopub.status.idle": "2025-01-13T09:19:04.621464Z",
     "shell.execute_reply": "2025-01-13T09:19:04.620613Z",
     "shell.execute_reply.started": "2025-01-13T09:18:08.297801Z"
    },
    "id": "nvjbDmdbsN9y",
    "outputId": "40f7fc39-a14d-443b-c278-7177fa20de81",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define your ForexTradingEnv and get_forex_data() as per your implementation\n",
    "# from your_forex_env import ForexTradingEnv, get_forex_data\n",
    "\n",
    "# Load and prepare data\n",
    "data = get_forex_data()\n",
    "\n",
    "# # testing whether the environment is correct\n",
    "# test_env= SequenceEnvironment(df=data,sequence_length=60)\n",
    "# check_env(test_env, warn=True)\n",
    "\n",
    "kwargs = {\"df\": data,\"sequence_length\": 60}\n",
    "envs = make_vec_env(SequenceEnvironment, n_envs=10, env_kwargs=kwargs)\n",
    "\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "save_freq = max(2000000 // envs.num_envs, 1)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=save_freq, save_path=checkpoint_dir, name_prefix='ppo_forex')\n",
    "# adding custom feature extractor\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=LSTMFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256, lstm_hidden_size=128),\n",
    "    lstm_hidden_size=256,\n",
    "    n_lstm_layers=1,\n",
    "    shared_lstm=False,\n",
    "    enable_critic_lstm=True,\n",
    ")\n",
    "\n",
    "def get_latest_checkpoint(checkpoint_dir):\n",
    "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('ppo_forex')]\n",
    "    if checkpoint_files:\n",
    "        checkpoint_files.sort(key=lambda x: os.path.getmtime(os.path.join(checkpoint_dir, x)), reverse=True)\n",
    "        return os.path.join(checkpoint_dir, checkpoint_files[0])\n",
    "    return None\n",
    "\n",
    "model_path = get_latest_checkpoint(checkpoint_dir)\n",
    "if model_path:\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    model = RecurrentPPO.load(model_path, env=envs, device=device)\n",
    "else:\n",
    "    print(\"No checkpoint found, initializing new model.\")\n",
    "    model = RecurrentPPO(\n",
    "        \"MlpLstmPolicy\",\n",
    "        envs,\n",
    "        tensorboard_log=\"./logs\",\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        learning_rate = 0.0001,\n",
    "        ent_coef = 0.8,\n",
    "        verbose=2,\n",
    "        device=device)\n",
    "\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=10_000,\n",
    "        tb_log_name=\"first_run\",\n",
    "        progress_bar=False,\n",
    "        callback=checkpoint_callback)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving current model...\")\n",
    "    model.save(os.path.join(checkpoint_dir, 'ppo_forex_interrupt'))\n",
    "    print(f\"Model saved to {os.path.join(checkpoint_dir, 'ppo_forex_interrupt')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-13T09:04:05.518689Z",
     "iopub.status.idle": "2025-01-13T09:04:05.518999Z",
     "shell.execute_reply": "2025-01-13T09:04:05.518851Z"
    },
    "id": "VHg7cUtsN4Eo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "balance_history = [[] for _ in range(envs.num_envs)]\n",
    "\n",
    "obs = envs.reset()\n",
    "lstm_states = None\n",
    "episode_starts = np.ones((envs.num_envs,), dtype=bool)\n",
    "\n",
    "while True:\n",
    "    action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "    print(action)\n",
    "    obs, rewards, dones, infos = envs.step(action)\n",
    "    # print(obs)\n",
    "    \n",
    "    \n",
    "    # Append the balance for each environment\n",
    "    for i, info in enumerate(infos):\n",
    "        balance_history[i].append(info[\"balance\"])\n",
    "        print(info[\"balance\"])\n",
    "    \n",
    "    # print(f\"action = \\n {action}\\n\")\n",
    "    episode_starts = dones\n",
    "    if dones.any():\n",
    "        break\n",
    "\n",
    "print(\"Evaluation complete!\")\n",
    "\n",
    "# Plot the balance history\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(envs.num_envs):\n",
    "    plt.plot(balance_history[i], label=f\"Env {i + 1}\")\n",
    "\n",
    "plt.title(\"Balance Over Steps for All Environments\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# obs = envs.reset()\n",
    "# lstm_states = None\n",
    "# episode_starts = np.ones((envs.num_envs,), dtype=bool)\n",
    "# while True:\n",
    "#     action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "#     obs, rewards, dones, info = envs.step(action)\n",
    "#     print(f\"action = \\n {action}\\n\")\n",
    "#     episode_starts = dones\n",
    "#     if dones.any():\n",
    "#         break\n",
    "# print(\"Evaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-13T09:04:05.519627Z",
     "iopub.status.idle": "2025-01-13T09:04:05.520012Z",
     "shell.execute_reply": "2025-01-13T09:04:05.519849Z"
    },
    "id": "FxckElBVsN9y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "model_path = get_latest_checkpoint(checkpoint_dir)\n",
    "FileLink(model_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6411871,
     "sourceId": 10354021,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6418935,
     "sourceId": 10363867,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6419707,
     "sourceId": 10364940,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
